{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d6cc2c",
   "metadata": {},
   "source": [
    "# OpenSearch MCP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d9bd47",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to set up and use OpenSearch MCP server in both stdio and SSE modes, including server configuration and tool execution. For complete documentation, see [opensearch-mcp-server-py](https://github.com/opensearch-project/opensearch-mcp-server-py) repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8bcc9f",
   "metadata": {},
   "source": [
    "## Stdio Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e97e01d",
   "metadata": {},
   "source": [
    "Configure MCP server with `stdio` protocol using the sample below. This configuration works with both [Claude Desktop](https://modelcontextprotocol.io/quickstart/user) and [Q Developer CLI](https://github.com/aws/amazon-q-developer-cli). For more detailed information, see the OpenSearch MCP server [user guide](https://github.com/opensearch-project/opensearch-mcp-server-py/blob/main/USER_GUIDE.md#quick-start)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9b482",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "    \"mcpServers\": {\n",
    "        \"opensearch-mcp-server\": {\n",
    "            \"command\": \"uvx\",\n",
    "            \"args\": [\n",
    "                \"opensearch_mcp_server_py\"\n",
    "            ],\n",
    "            \"env\": {\n",
    "                // Optional\n",
    "                \"OPENSEARCH_URL\": \"<your_opensearch_domain_url>\",\n",
    "                \n",
    "                // For OpenSearch Serverless\n",
    "                \"AWS_OPENSEARCH_SERVERLESS\": \"true\",  // Set to \"true\" for OpenSearch Serverless\n",
    "\n",
    "                // For Basic Authentication\n",
    "                \"OPENSEARCH_USERNAME\": \"<your_opensearch_domain_username>\",\n",
    "                \"OPENSEARCH_PASSWORD\": \"<your_opensearch_domain_password>\",\n",
    "\n",
    "                // For IAM Role Authentication\n",
    "                \"AWS_REGION\": \"<your_aws_region>\",\n",
    "                \"AWS_ACCESS_KEY_ID\": \"<your_aws_access_key>\",\n",
    "                \"AWS_SECRET_ACCESS_KEY\": \"<your_aws_secret_access_key>\",\n",
    "                \"AWS_SESSION_TOKEN\": \"<your_aws_session_token>\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7d48b2",
   "metadata": {},
   "source": [
    "## SSE Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ef6932-8211-4671-9e4a-94b1ca167ab5",
   "metadata": {},
   "source": [
    "Follow these steps to set up MCP server with `sse` protocol using OpenSearch MCP client:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80418586",
   "metadata": {},
   "source": [
    "### 1. Install `opensearch-mcp-server-py` package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639320a5",
   "metadata": {},
   "source": [
    "Opensearch-mcp-server-py can be installed from [PyPI](https://pypi.org/project/opensearch-mcp-server-py/) via pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898dbb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opensearch-mcp-server-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3097d9-f1d6-4173-839b-80c51c8500cd",
   "metadata": {},
   "source": [
    "### 2. Set preferred authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6050684",
   "metadata": {},
   "source": [
    "Both basic authentication and IAM authentication can be configured via either global environment variables or environment variables in agent MCP config file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293b06d7",
   "metadata": {},
   "source": [
    "#### a. Basic Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0a1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENSEARCH_URL'] = \"<your_opensearch_domain_url>\"\n",
    "os.environ['OPENSEARCH_USERNAME'] = \"<your_opensearch_domain_username>\"\n",
    "os.environ['OPENSEARCH_PASSWORD'] = \"<your_opensearch_domain_password>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfcd24b",
   "metadata": {},
   "source": [
    "#### b. IAM Role Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd135d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENSEARCH_URL'] = \"<your_opensearch_domain_url>\"\n",
    "os.environ['AWS_REGION'] = \"<your_aws_region>\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = \"<your_aws_access_key>\"\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = \"<your_aws_secret_access_key>\"\n",
    "os.environ['AWS_SESSION_TOKEN'] = \"<your_aws_session_token>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5840af6",
   "metadata": {},
   "source": [
    "#### c. OpenSearch Serverless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b4329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENSEARCH_URL'] = \"<your_opensearch_domain_url>\"\n",
    "os.environ['AWS_OPENSEARCH_SERVERLESS'] = True\n",
    "os.environ['AWS_REGION'] = \"<your_aws_region>\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = \"<your_aws_access_key>\"\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = \"<your_aws_secret_access_key>\"\n",
    "os.environ['AWS_SESSION_TOKEN'] = \"<your_aws_session_token>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51866d24",
   "metadata": {},
   "source": [
    "### 3. Run the server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c6219a-f63c-4fbe-944c-4e1da90ed6c4",
   "metadata": {},
   "source": [
    "By default, the server will run on port **9900**. You can change the port number by specifying the port number in below command, for example:\n",
    "\n",
    "`[\"python\", \"-m\", \"mcp_server_opensearch\", \"--transport\", \"sse\", \"--port\", \"<your_desired_port_number>\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b332fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "process = subprocess.Popen(\n",
    "    [\"python\", \"-m\", \"mcp_server_opensearch\", \"--transport\", \"sse\"],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a833c",
   "metadata": {},
   "source": [
    "> Note: The server will keep running in the background, so you can continue using the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87843ec",
   "metadata": {},
   "source": [
    "### 4. Create an MCP connector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db31492a",
   "metadata": {},
   "source": [
    "An MCP connector stores connection details and credentials for your MCP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf1523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "# Change these variables with your OpenSearch and MCP server information\n",
    "opensearch_domain_url = \"<your_opensearch_domain_url>\"\n",
    "opensearch_domain_username = \"<your_opensearch_domain_username>\"\n",
    "opensearch_domain_password = \"<your opensearch_domain_password\"\n",
    "mcp_server_url = \"<your_mcp_server_url>\"  # For example \"http://localhost:9900\"\n",
    "mcp_server_api_key = \"<your_mcp_server_api_key>\"  # For example \"secret-token\"\n",
    "\n",
    "# Configure settings needed to enable MCP protocol\n",
    "payload = {\n",
    "  \"persistent\": {\n",
    "    \"plugins.ml_commons.trusted_connector_endpoints_regex\": [\n",
    "        mcp_server_url,\n",
    "        \"https://api.openai.com/v1/chat/completions\"\n",
    "    ],\n",
    "    \"plugins.ml_commons.mcp_connector_enabled\": \"true\"\n",
    "  }\n",
    "}\n",
    "settings_response = requests.put(f'{opensearch_domain_url}/_cluster/settings',\n",
    "                        auth=HTTPBasicAuth(opensearch_domain_username, opensearch_domain_password),\n",
    "                        json=payload,\n",
    "                        headers={\"Content-Type\": \"application/json\"})\n",
    "print(settings_response.text)\n",
    "\n",
    "# Create an MCP connector\n",
    "payload = {\n",
    "    \"name\": \"My MCP Connector\",\n",
    "    \"description\": \"Connects to the OpenSearch MCP server\",\n",
    "    \"version\": 1,\n",
    "    \"protocol\": \"mcp_sse\",\n",
    "    \"url\": mcp_server_url,\n",
    "    \"credential\": {\n",
    "        \"mcp_server_key\": mcp_server_api_key\n",
    "    },\n",
    "    \"headers\": {\n",
    "        \"Authorization\": \"Bearer ${credential.mcp_server_key}\"\n",
    "    }\n",
    "}\n",
    "connector_response = requests.post(f'{opensearch_domain_url}/_plugins/_ml/connectors/_create',\n",
    "                        auth=HTTPBasicAuth(opensearch_domain_username, opensearch_domain_password),\n",
    "                        json=payload,\n",
    "                        headers={\"Content-Type\": \"application/json\"})\n",
    "print(connector_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b739bf62",
   "metadata": {},
   "source": [
    "### 5. Register a remote model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f240cca4",
   "metadata": {},
   "source": [
    "Register any externally hosted large language model (LLM) using a connector. For a list of supported models, see [Supported connectors](https://docs.opensearch.org/docs/latest/ml-commons-plugin/remote-models/supported-connectors/).\n",
    "\n",
    "In this notebook, we're using OpenAI chat model, but you can register any model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adee6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this variable with your model API key\n",
    "openai_api_key = \"<your_openai_api_key>\"\n",
    "\n",
    "# Create OpenAI chat model\n",
    "payload = {\n",
    "    \"name\": \"My OpenAI model: gpt-4\",\n",
    "    \"function_name\": \"remote\",\n",
    "    \"description\": \"Test model registration\",\n",
    "    \"connector\": {\n",
    "        \"name\": \"My OpenAI Connector: gpt-4\",\n",
    "        \"description\": \"Connector for the OpenAI chat model\",\n",
    "        \"version\": 1,\n",
    "        \"protocol\": \"http\",\n",
    "        \"parameters\": {\n",
    "            \"model\": \"gpt-4o\"\n",
    "        },\n",
    "        \"credential\": {\n",
    "            \"openAI_key\": openai_api_key\n",
    "        },\n",
    "        \"actions\": [{\n",
    "            \"action_type\": \"predict\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"https://api.openai.com/v1/chat/completions\",\n",
    "            \"headers\": {\n",
    "                \"Authorization\": \"Bearer ${credential.openAI_key}\"\n",
    "            },\n",
    "            \"request_body\": \"{ \\\"model\\\": \\\"${parameters.model}\\\", \\\"messages\\\": [{\\\"role\\\":\\\"developer\\\",\\\"content\\\":\\\"${parameters.system_instruction}\\\"},${parameters._chat_history:-}{\\\"role\\\":\\\"user\\\",\\\"content\\\":\\\"${parameters.prompt}\\\"}${parameters._interactions:-}], \\\"tools\\\": [${parameters._tools:-}],\\\"parallel_tool_calls\\\":${parameters.parallel_tool_calls},\\\"tool_choice\\\": \\\"${parameters.tool_choice}\\\" }\"\n",
    "        }]\n",
    "    }\n",
    "}\n",
    "response = requests.post(f'{opensearch_domain_url}/_plugins/_ml/models/_register',\n",
    "                        auth=HTTPBasicAuth(opensearch_domain_username, opensearch_domain_password),\n",
    "                        json=payload,\n",
    "                        headers={\"Content-Type\": \"application/json\"})\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4666ec",
   "metadata": {},
   "source": [
    "### 6. Register an agent for accessing MCP tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339141ce",
   "metadata": {},
   "source": [
    "Currently, MCP tools can only be used with [conversational](https://docs.opensearch.org/docs/latest/ml-commons-plugin/agents-tools/agents/conversational/) or [plan-execute-reflect](https://docs.opensearch.org/docs/latest/ml-commons-plugin/agents-tools/agents/plan-execute-reflect/) agent types.\n",
    "\n",
    "In this notebook, we'll use conversational agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4eadd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these variables with the connector ID and model ID from previous steps\n",
    "mcp_connector_id = \"<your_mcp_connector_id>\"  # From step 4\n",
    "llm_model_id = \"<your_llm_model_id>\"  # From step 5\n",
    "\n",
    "# Register a conversational agent\n",
    "payload = {\n",
    "    \"name\": \"OpenSearch MCP server\",\n",
    "    \"type\": \"conversational\",\n",
    "    \"description\": \"Uses MCP to information related to OpenSearch\",\n",
    "    \"llm\": {\n",
    "        \"model_id\": llm_model_id,\n",
    "        \"parameters\": {\n",
    "            \"max_iteration\": 5,\n",
    "            \"system_instruction\": \"You are a helpful assistant.\",\n",
    "            \"prompt\": \"${parameters.question}\"\n",
    "        }\n",
    "    },\n",
    "    \"memory\": {\n",
    "        \"type\": \"conversation_index\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"_llm_interface\": \"openai/v1/chat/completions\",\n",
    "        \"mcp_connectors\": [{\n",
    "            \"mcp_connector_id\": mcp_connector_id\n",
    "        }]\n",
    "    },\n",
    "    \"app_type\": \"os_chat\"\n",
    "}\n",
    "response = requests.post(f'{opensearch_domain_url}/_plugins/_ml/agents/_register',\n",
    "                        auth=HTTPBasicAuth(opensearch_domain_username, opensearch_domain_password),\n",
    "                        json=payload,\n",
    "                        headers={\"Content-Type\": \"application/json\"})\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8900e338",
   "metadata": {},
   "source": [
    "### 7. Execute the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2710c5-d32c-4ecf-811d-44743ac50746",
   "metadata": {},
   "source": [
    "Example questions you can ask the agent about OpenSearch:\n",
    "- `ListIndexTool` : List all indices in my OpenSearch cluster?\n",
    "- `GetShardsTool` : Can you get the shards information of an index called .plugins-ml-config in my OpenSearch cluster?\n",
    "- `ClusterHealthTool` : Can you check my OpenSearch cluster health?\n",
    "- `SearchIndexTool` : I have an index called sample_data_ecommerce, can you show me the email addresses of 20 customers from this index?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505863b5-8290-4016-8f53-f9d602ae04ce",
   "metadata": {},
   "source": [
    "> See more available tools in [OpenSearch MCP server](https://github.com/opensearch-project/opensearch-mcp-server-py/blob/main/README.md#available-tools) repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4b091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these variables with the agent ID from previous step and the question for the agent\n",
    "agent_id = \"<your_agent_id>\"  # From step 6\n",
    "question = \"<your_question>\"\n",
    "\n",
    "# Execute the agent\n",
    "payload = {\n",
    "  \"parameters\": {\n",
    "    \"question\": question,\n",
    "    \"verbose\": True\n",
    "  }\n",
    "}\n",
    "response = requests.post(f'{opensearch_domain_url}/_plugins/_ml/agents/{agent_id}/_execute',\n",
    "                        auth=HTTPBasicAuth(opensearch_domain_username, opensearch_domain_password),\n",
    "                        json=payload,\n",
    "                        headers={\"Content-Type\": \"application/json\"})\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
